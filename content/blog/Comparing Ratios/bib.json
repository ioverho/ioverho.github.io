[
  {"id":"borensteinIntroductionMetaanalysis2013","citation-key":"borensteinIntroductionMetaanalysis2013","edition":"Nachdr.","editor":[{"family":"Borenstein","given":"Michael"}],"event-place":"Chichester","ISBN":"978-0-470-05724-7","issued":{"date-parts":[["2013"]]},"language":"en","number-of-pages":"421","publisher":"Wiley","publisher-place":"Chichester","source":"K10plus ISBN","title":"Introduction to meta-analysis","type":"book"},
  {"id":"gelmanBayesianDataAnalysis2013","abstract":"Winner of the 2016 De Groot Prize from the International Society for Bayesian AnalysisNow in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors―all leaders in the statistics community―introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice.New to the Third EditionFour new chapters on nonparametric modelingCoverage of weakly informative priors and boundary-avoiding priorsUpdated discussion of cross-validation and predictive information criteriaImproved convergence monitoring and effective sample size calculations for iterative simulationPresentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagationNew and revised software codeThe book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.","author":[{"family":"Gelman","given":"Andrew"},{"family":"Carlin","given":"John B."},{"family":"Stern","given":"Hal S."},{"family":"Dunson","given":"David B."},{"family":"Vehtari","given":"Aki"},{"family":"Rubin","given":"Donald B."}],"citation-key":"gelmanBayesianDataAnalysis2013","edition":"3rd edition","event-place":"Boca Raton London New York","ISBN":"978-1-4398-4095-5","issued":{"date-parts":[["2013",11,1]]},"language":"English","number-of-pages":"675","publisher":"Chapman and Hall/CRC","publisher-place":"Boca Raton London New York","source":"Amazon","title":"Bayesian Data Analysis","type":"book"},
  {"id":"goutteProbabilisticInterpretationPrecision2005","abstract":"We address the problems of 1/ assessing the conﬁdence of the standard point estimates, precision, recall and F -score, and 2/ comparing the results, in terms of precision, recall and F -score, obtained using two diﬀerent methods. To do so, we use a probabilistic setting which allows us to obtain posterior distributions on these performance indicators, rather than point estimates. This framework is applied to the case where diﬀerent methods are run on diﬀerent datasets from the same source, as well as the standard situation where competing results are obtained on the same data.","author":[{"family":"Goutte","given":"Cyril"},{"family":"Gaussier","given":"Eric"}],"citation-key":"goutteProbabilisticInterpretationPrecision2005","issued":{"date-parts":[["2005",1]]},"language":"en","source":"Zotero","title":"A Probabilistic Interpretation of Precision, Recall and F -score, with Implication for Evaluation","type":"article-journal"},
  {"id":"harrerWelcomeDoingMetaAnalysis","abstract":"This is a guide on how to conduct Meta-Analyses in R.","author":[{"family":"Harrer","given":"Mathias"},{"family":"Cuijpers","given":"Pim"},{"family":"Furukawa","given":"Toshi A."},{"family":"Ebert","given":"David D."}],"citation-key":"harrerWelcomeDoingMetaAnalysis","language":"en","source":"bookdown.org","title":"Welcome! | Doing Meta-Analysis in R","type":"book","URL":"https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/"},
  {"id":"kruschkeBayesianEstimationSupersedes2013","abstract":"Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms.","author":[{"family":"Kruschke","given":"John K."}],"citation-key":"kruschkeBayesianEstimationSupersedes2013","container-title":"Journal of Experimental Psychology: General","container-title-short":"Journal of Experimental Psychology: General","DOI":"10.1037/a0029146","ISSN":"1939-2222, 0096-3445","issue":"2","issued":{"date-parts":[["2013"]]},"language":"en","page":"573-603","source":"DOI.org (Crossref)","title":"Bayesian estimation supersedes the t test.","type":"article-journal","URL":"https://doi.apa.org/doi/10.1037/a0029146","volume":"142"},
  {"id":"takahashiConfidenceIntervalMicroaveraged2022","abstract":"A binary classification problem is common in medical field, and we often use sensitivity, specificity, accuracy, negative and positive predictive values as measures of performance of a binary predictor. In computer science, a classifier is usually evaluated with precision (positive predictive value) and recall (sensitivity). As a single summary measure of a classifier’s performance, F1 score, defined as the harmonic mean of precision and recall, is widely used in the context of information retrieval and information extraction evaluation since it possesses favorable characteristics, especially when the prevalence is low. Some statistical methods for inference have been developed for the F1 score in binary classification problems; however, they have not been extended to the problem of multi-class classification. There are three types of F1 scores, and statistical properties of these F1 scores have hardly ever been discussed. We propose methods based on the large sample multivariate central limit theorem for estimating F1 scores with confidence intervals.","author":[{"family":"Takahashi","given":"Kanae"},{"family":"Yamamoto","given":"Kouji"},{"family":"Kuchiba","given":"Aya"},{"family":"Koyama","given":"Tatsuki"}],"citation-key":"takahashiConfidenceIntervalMicroaveraged2022","container-title":"Applied intelligence (Dordrecht, Netherlands)","container-title-short":"Appl Intell (Dordr)","DOI":"10.1007/s10489-021-02635-5","ISSN":"0924-669X","issue":"5","issued":{"date-parts":[["2022",3]]},"page":"4961-4972","PMCID":"PMC8936911","PMID":"35317080","source":"PubMed Central","title":"Confidence interval for micro-averaged F1 and macro-averaged F1 scores","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/","volume":"52"}
]
