[
  {"id":"devlinBERTPretrainingDeep2019a","abstract":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Devlin","given":"Jacob"},{"family":"Chang","given":"Ming-Wei"},{"family":"Lee","given":"Kenton"},{"family":"Toutanova","given":"Kristina"}],"citation-key":"devlinBERTPretrainingDeep2019a","issued":{"date-parts":[["2019",5,24]]},"language":"en","number":"arXiv:1810.04805","publisher":"arXiv","source":"arXiv.org","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","title-short":"BERT","type":"article","URL":"http://arxiv.org/abs/1810.04805"},
  {"id":"eikemaSamplingBasedApproximationsMinimum2022","abstract":"In NMT we search for the mode of the model distribution to form predictions. The mode and other high-probability translations found by beam search have been shown to often be inadequate in a number of ways. This prevents improving translation quality through better search, as these idiosyncratic translations end up selected by the decoding algorithm, a problem known as the beam search curse. Recently, an approximation to minimum Bayes risk (MBR) decoding has been proposed as an alternative decision rule that would likely not suffer from the same problems. We analyse this approximation and establish that it has no equivalent to the beam search curse. We then design approximations that decouple the cost of exploration from the cost of robust estimation of expected utility. This allows for much larger hypothesis spaces, which we show to be beneficial. We also show that mode-seeking strategies can aid in constructing compact sets of promising hypotheses and that MBR is effective in identifying good translations in them. We conduct experiments on three language pairs varying in amounts of resources available: English into and from German, Romanian, and Nepali.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Eikema","given":"Bryan"},{"family":"Aziz","given":"Wilker"}],"citation-key":"eikemaSamplingBasedApproximationsMinimum2022","issued":{"date-parts":[["2022",10,25]]},"language":"en","number":"arXiv:2108.04718","publisher":"arXiv","source":"arXiv.org","title":"Sampling-Based Approximations to Minimum Bayes Risk Decoding for Neural Machine Translation","type":"article","URL":"http://arxiv.org/abs/2108.04718"},
  {"id":"kiegelandRevisitingWeaknessesReinforcement2021","abstract":"Policy gradient algorithms have found wide adoption in NLP, but have recently become subject to criticism, doubting their suitability for NMT. Choshen et al. (2020) identify multiple weaknesses and suspect that their success is determined by the shape of output distributions rather than the reward. In this paper, we revisit these claims and study them under a wider range of conﬁgurations. Our experiments on in-domain and cross-domain adaptation reveal the importance of exploration and reward scaling, and provide empirical counterevidence to these claims.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Kiegeland","given":"Samuel"},{"family":"Kreutzer","given":"Julia"}],"citation-key":"kiegelandRevisitingWeaknessesReinforcement2021","container-title":"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","DOI":"10.18653/v1/2021.naacl-main.133","issued":{"date-parts":[["2021"]]},"language":"en","page":"1673-1681","source":"arXiv.org","title":"Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation","type":"paper-conference","URL":"http://arxiv.org/abs/2106.08942"},
  {"id":"leeDeterministicNonAutoregressiveNeural2018","abstract":"We propose a conditional non-autoregressive neural sequence model based on iterative reﬁnement. The proposed model is designed based on the principles of latent variable models and denoising autoencoders, and is generally applicable to any sequence generation task. We extensively evaluate the proposed model on machine translation (En↔De and En↔Ro) and image caption generation, and observe that it signiﬁcantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Lee","given":"Jason"},{"family":"Mansimov","given":"Elman"},{"family":"Cho","given":"Kyunghyun"}],"citation-key":"leeDeterministicNonAutoregressiveNeural2018","issued":{"date-parts":[["2018",8,27]]},"language":"en","number":"arXiv:1802.06901","publisher":"arXiv","source":"arXiv.org","title":"Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement","type":"article","URL":"http://arxiv.org/abs/1802.06901"},
  {"id":"ranzatoSequenceLevelTraining2016","abstract":"Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Ranzato","given":"Marc'Aurelio"},{"family":"Chopra","given":"Sumit"},{"family":"Auli","given":"Michael"},{"family":"Zaremba","given":"Wojciech"}],"citation-key":"ranzatoSequenceLevelTraining2016","issued":{"date-parts":[["2016",5,6]]},"language":"en","number":"arXiv:1511.06732","publisher":"arXiv","source":"arXiv.org","title":"Sequence Level Training with Recurrent Neural Networks","type":"article","URL":"http://arxiv.org/abs/1511.06732"},
  {"id":"wangExposureBiasHallucination2020","abstract":"The standard training algorithm in neural machine translation (NMT) suffers from exposure bias, and alternative algorithms have been proposed to mitigate this. However, the practical impact of exposure bias is under debate. In this paper, we link exposure bias to another well-known problem in NMT, namely the tendency to generate hallucinations under domain shift. In experiments on three datasets with multiple test domains, we show that exposure bias is partially to blame for hallucinations, and that training with Minimum Risk Training, which avoids exposure bias, can mitigate this. Our analysis explains why exposure bias is more problematic under domain shift, and also links exposure bias to the beam search problem, i.e. performance deterioration with increasing beam size. Our results provide a new justiﬁcation for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets, they can increase model robustness to domain shift.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Wang","given":"Chaojun"},{"family":"Sennrich","given":"Rico"}],"citation-key":"wangExposureBiasHallucination2020","issued":{"date-parts":[["2020",5,7]]},"language":"en","number":"arXiv:2005.03642","publisher":"arXiv","source":"arXiv.org","title":"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation","type":"article","URL":"http://arxiv.org/abs/2005.03642"}
]
