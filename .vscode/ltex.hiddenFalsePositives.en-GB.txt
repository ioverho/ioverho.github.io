{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qeither node is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q\nany node that is not a mutual descendant of \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, which we call non-colliders\nany node that is a mutual descendant of \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, which we call colliders\\E$"}
{"rule":"PUNCTUATION_PARAGRAPH_END","sentence":"^\\Qeither node is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q\nany node that is not a mutual descendant of \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, which we call non-colliders\nany node that is a mutual descendant of \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, which we call colliders\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwhich we can summarize in a pleasing diagram.\\E$"}
{"rule":"OXFORD_SPELLING_Z_NOT_S","sentence":"^\\QIn this paper, we propose a novel evaluation setup for model generalisation based on our few-shot subgraph sampling approach.\\E$"}
{"rule":"OXFORD_SPELLING_Z_NOT_S","sentence":"^\\QThis setup tests for generalisation through few labelled examples in local explorations of a larger graph, emulating more realistic application settings.\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QAny hope for a nicely intuitive metric went out the window as soon as we went to an odds ratio, and adding a logarithm only makes it worse.\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QOdds are already a ratio of ratios, so the odds ratio is a ratio of ratios of ratios???\\E$"}
{"rule":"PHRASE_REPETITION","sentence":"^\\QOdds are already a ratio of ratios, so the odds ratio is a ratio of ratios of ratios???\\E$"}
{"rule":"PHRASE_REPETITION","sentence":"^\\QOdds are already a ratio of ratios, so the log odds ratio is a logarithm of a ratio of ratios of ratios???\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_GB","sentence":"^\\QFor example, both Goutte & Gaussier (2005) and Takahashi et al. (2022) Confidence interval for micro-averaged F1 and macro-averaged F1 scores dedicate papers to finding exact distributions for the F1-score.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_GB","sentence":"^\\QThe model recommended by Harrer et al. (2021) is as follows, $$\\begin{align} \\mu &\\sim\\mathcal{N}(0, 1) \\\\ \\tau &\\sim\\text{HalfCauchy}(0,0.5) \\\\ \\theta_{j}&\\sim\\mathcal{N}(\\mu, \\tau^2) \\\\ \\hat{\\theta}{j}&\\sim\\mathcal{N}(\\theta, \\sigma{k}^2) \\end{align}\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_GB","sentence":"^\\QTo estimate the probability that two probabilities are different, we can just count how often, relatively, a sample from one distribution is larger than from the other distribution: $$\\begin{align} p(r_2>r_1)&\\approx \\frac{1}{K}\\sum_{k=1}^{K}\\mathbb{1}(\\tilde{r}{2,k}>\\tilde{r}{1,k}) \\\\ \\tilde{r}{1,k}&\\sim\\text{Beta}(\\alpha+r_1N_1, \\beta+(N_1-r_1N_1)), \\\\ \\tilde{r}{2,k}&\\sim\\text{Beta}(\\alpha+r_2N_2, \\beta+(N_2-r_2N_2)),\\E$"}
{"rule":"EN_UNPAIRED_BRACKETS","sentence":"^\\Q^4: Another reason to read this blog post is the philosophical musing at the end: “… many statisticians … turn to statistics as a tool to hide from the realities of a rapidly changing world, clinging to thin strands of imagined certainty, and hiding doubt in complexity.\" chef's kiss\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QFor example, for a probability of 1 in a million (1e-6) to 2 in a million (2e-6), the odds ratio is \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q (pretty large).\\E$"}
